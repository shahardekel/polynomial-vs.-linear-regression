# polynomial-vs.-linear-regression
How to perform polynomial regression with linear regression tools using python


Given train data (ğ‘¥1 = 0, ğ‘¦1 = âˆ’1.25), (ğ‘¥2 = 0.5, ğ‘¦2 = âˆ’0.6), (ğ‘¥3 = 2, ğ‘¦3 = âˆ’4.85)
and test data (ğ‘¥4 = âˆ’1, ğ‘¦4 = âˆ’5.2), (ğ‘¥5 = 1, ğ‘¦5 = âˆ’0.9), (ğ‘¥6 = 3, ğ‘¦6 = âˆ’13):

a. Define a 3 Ã— 1 two-dimensional matrix called X_train in which each row is an observation from the training data, and define a (one-dimensional) vector called y_train which contains the responses of these observations (in the same order). 
Repeat this process with the test data (X_test, y_test).

b. Calculate the regular LS estimators ğ‘¤Ì‚0, ğ‘¤Ì‚1 using only the training data with
sklearn built-in functions.
What are the predicted values for X_test?

c. What is the MSE of the regression on the train data?
What is the MSE of the regression on the test data?
What can you conclude from these values?

d. Write a function which receives a np-array of explanatory variables X and a np-array of responses Y and returns the least squares estimator using the closedform expression we saw in class.
There is no need to check that the input is valid. (donâ€™t forget to add ones!)

e. Plot the regression line in a dashed (--) black line. Scatter (with plt.scatter()) the points in the train data with marker='*' and scatter the points in the test data with marker='o'. You should use legend (for train and test data) and label the axes. The range in the x axis should be np.arange(-3, 5).
Does it look like the regression fit the data?

f. We will now try to perform a 2nd degree polynomial regression, meaning we will assume now that ğ‘¦ğ‘– â‰ˆ ğ›¾0 + ğ›¾1 âˆ™ ğ‘¥ğ‘– + ğ›¾2 âˆ™ ğ‘¥ğ‘–^2

  1. If we would mark ğ‘§ğ‘– = (ğ‘¥ğ‘–, ğ‘¥ğ‘–^2)^ğ‘‡ , how can we write ğ‘¦ğ‘– in a linear form?
  2. Define a 3 Ã— 2 matrix called Z_train in which the first column corresponds to ğ‘¥ğ‘– and the second column corresponds to ğ‘¥ğ‘–^2 for each    ğ‘¥ğ‘– in the train data (in the same order as in section a.). Repeat this process with the test data (Z_test).
  3. Use the function you wrote in section d. to calculate the LS estimators ğ›¾Ì‚ =(ğ›¾Ì‚0, ğ›¾Ì‚1, ğ›¾Ì‚2)^ğ‘‡ using only the training data (Z_train and y_train). What is the MSE of the regression on the train data? What is the MSE on the test data?
  4. Plot the corresponding 2nd degree polynomial function in a red dashed line, alongside the original regression line in a black dashed line. Scatter the points in the training data (with marker='*'), as well as the points in the testing data (with marker='o'). You should use legend for both data type (train/test) and regression type (linear/polynomial) and label the axes. The range in the x axis should be np.arange(-3, 5). Name the plot 'Polynomial Regression vs. Linear Regression'.
 Which regression seems to perform better?
 
 g. Which assumption did not hold, thus making the linear regression to fail?
